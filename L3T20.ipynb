{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eHGm8RQlK46m"
   },
   "source": [
    "# Get and explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-erlYw1jXtgh"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goZIhX8nII4T"
   },
   "outputs": [],
   "source": [
    "# Make results reproducible - set random seed\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v_fEysQHII4W",
    "tags": []
   },
   "outputs": [],
   "source": [
    "negative_file = \"negative.txt\"\n",
    "positive_file = \"positive.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0rWm4yycII4Y",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - helper function to load and preprocess data\n",
    "def filter_words(line):    \n",
    "    line = re.sub(r'[^\\w\\s]','',line.rstrip())\n",
    "    words = line.split(\" \") \n",
    "    words = [i.lower() for i in words if i]      \n",
    "    return \" \".join(words)\n",
    "\n",
    "def load_data(filename):\n",
    "    thefile = open(filename, 'r') \n",
    "    lines = thefile.readlines() \n",
    "\n",
    "    data = []\n",
    "    for l in range(0,len(lines)): \n",
    "        if(lines[l-1].strip() == \"<title>\"): \n",
    "            theline = filter_words(lines[l])\n",
    "            if(len(theline) < 50):\n",
    "                data.append(theline)            \n",
    "            \n",
    "    return data\n",
    "\n",
    "# Helper function to convert categorical data to class label\n",
    "def to_word_label(y):\n",
    "    y = to_class(y)   \n",
    "    return [\"positive\" if i==0 else \"negative\" for i in y]\n",
    "\n",
    "# Helper function to convert class label to numeric label\n",
    "def to_numeric_label(y):\n",
    "    return [0 if i==\"positive\" else 1 for i in word_labels]\n",
    "\n",
    "# Helper function: this function needs to be called before sending arrays to sklearn metrics,\n",
    "# it converts back to class form from categorical form. ie: [1,0] --> 0, [0,1] --> 1\n",
    "def to_class(y):\n",
    "    return np.argmax(y,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "jjGUiFm9II4b",
    "outputId": "aa5eb89b-85f2-4d61-f33a-b00361b19a41",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book', 'to the point and beautifully illustrated', 'at least somebody has got it', 'beautifully written heartwarming story', 'an excellent cookbook full of delicious recipes', 'an outstanding resource']\n",
      "['horrible book horrible', 'shallow selfindulgence', 'horrible book horrible', 'disappointment', 'a disappointing mess', 'save your money there are better books out there', 'thank you but no thanks', 'unendurable', 'the hard way', 'some good info among the political commercial']\n"
     ]
    }
   ],
   "source": [
    "positive = load_data(positive_file)\n",
    "negative = load_data(negative_file)\n",
    "\n",
    "print(positive[0:10])\n",
    "print(negative[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrgEYOOCII4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Do not modify - Combines the positive and negative reviews into a single list and create labels\n",
    "data = positive + negative\n",
    "word_labels = [\"positive\"] * len(positive) + [\"negative\"] * len(negative) \n",
    "\n",
    "# Converts labels to numbers in one-hot encoding - [1, 0] (positive) or [0, 1] (negative)\n",
    "from keras.utils import to_categorical\n",
    "labels  = to_categorical(to_numeric_label(word_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "97Uh2uBpII4l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Write some code to investigate the dataset. \n",
    "# - Calculate and report the mean review size, its standard deviation and create a boxplot.\n",
    "\n",
    "# creating the dataframe\n",
    "df_fin = pd.DataFrame(labels,data).reset_index()\n",
    "\n",
    "# adding the total words to the totalwords col \n",
    "df_fin[\"totalwords\"] = df_fin[\"index\"].str.split().str.len()\n",
    "\n",
    "# calculating the STD and mean \n",
    "df_mean = df_fin[\"totalwords\"].mean()\n",
    "df_std = df_fin[\"totalwords\"].std()\n",
    "\n",
    "# - Perform any other dataset investigation that you feel would be valuable\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean :\n",
      "4.336865588399331\n",
      "STD :\n",
      "2.170280849250691\n"
     ]
    }
   ],
   "source": [
    "# print the mean and STD of the Totalwords column \n",
    "print(\"mean :\") \n",
    "print(df_mean)\n",
    "print(\"STD :\") \n",
    "print(df_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANJUlEQVR4nO3df2xd5XnA8e8zQu0SMtIq1KrKNG9TRWvRH5vuprW0zCFDQgOtXdetdGrFfmFFmzJKVjUu08Yfk6JEraJVbJPltAwkWDYVijotJQLR3IVNgzYBStKka6WRtqwUKNUEhNU027M/fGGZ48TX955r+6m/H8ny9fG5931jWd+8Or7nnMhMJEn1/NhyT0CS1BsDLklFGXBJKsqAS1JRBlySilqzlINt2LAhR0dHl3JIqSsnTpxg7dq1yz0NaV6HDh36XmZeOHf7kgZ8dHSUgwcPLuWQUlfa7Tbj4+PLPQ1pXhHxzfm2ewhFkooy4JJUlAGXpKIMuCQVZcAlqagFAx4Rt0TE0xFx5JRtn4iIr0XEYxFxd0SsH+gspQHZsmULw8PDbNy4keHhYbZs2bLcU5K61s0K/Fbgyjnb7gMuycy3Al8HPt7wvKSB27JlC1NTU2zfvp177rmH7du3MzU1ZcRVxoIBz8wDwPfnbLs3M092vnwQuGgAc5MGavfu3ezcuZOtW7cyPDzM1q1b2blzJ7t3717uqUldaeJEnt8F/v5M34yICWACYGRkhHa73cCQUv9mZmYYGxuj3W7zwgsv0G63GRsbY2Zmxt9TldBXwCPiT4CTwB1n2iczp4FpgFarlZ7tppViaGiIo0ePsnXr1lfOxNy1axdDQ0OelakSeg54RFwLXA1sSm/ro4Kuu+46tm3bBsDY2Bi7du1i27ZtbN68eZlnJnWnp4BHxJXANuCXMvPFZqckLY2bb74ZgBtvvJGZmRmGhobYvHnzK9ullS4WWjxHxB5gHNgAPAXcxOy7ToaAZzu7PZiZCy5bWq1WejErrURezEorWUQcyszW3O0LrsAz84PzbP5MI7OSJPXMMzElqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAOuVc078qiyJq4HLpX08h15du7cydjYGEePHn3l6oRe0EoVuALXquUdeVSdAdeqNTMzc9q1vzdv3szMzMwyzUhaHAOuVWtoaIipqan/t21qaoqhoaFlmpG0OB4D16rlHXlUnQHXquUdeVTdgnfkaZJ35NFK5R15tJKd6Y48HgOXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBW1YMAj4paIeDoijpyy7bURcV9EfKPz+TWDnaYkaa5uVuC3AlfO2TYJ3J+ZbwTu73wtSVpCCwY8Mw8A35+z+T3AbZ3HtwHvbXZakqSF9Ho52ZHMfBIgM5+MiNedaceImAAmAEZGRmi32z0OKXVv48aNSzLO/v37l2QcaT4Dvx54Zk4D0zB7OVkv2amlsNjLJI9O7uX4jqsGNBtpMHp9F8pTEfF6gM7np5ubkiSpG70G/B+AazuPrwU+38x0JEnd6uZthHuAfwUujognIuL3gB3AFRHxDeCKzteSpCW04DHwzPzgGb61qeG5SJIWwTMxJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSqqr4BHxA0R8dWIOBIReyJiuKmJSZLOrueAR8QbgD8CWpl5CXAOcE1TE5MknV2/h1DWAK+OiDXAecB3+p+SJKkba3p9Ymb+R0R8EvgW8F/AvZl579z9ImICmAAYGRmh3W73OqQ0UP5uqpqeAx4RrwHeA/wU8J/AZyPiQ5l5+6n7ZeY0MA3QarVyfHy858lKA7NvL/5uqpp+DqH8MvB4Zj6TmT8EPge8s5lpSZIW0k/AvwX8YkScFxEBbAKONTMtSdJCeg54Zj4E3Ak8DBzuvNZ0Q/OSJC2g52PgAJl5E3BTQ3ORJC2CZ2JKUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVFRfAY+I9RFxZ0R8LSKORcQ7mpqYJOns1vT5/E8B+zLz/RHxKuC8BuYkSepCzwGPiB8HLgN+GyAzXwJeamZakqSF9LMC/2ngGeBvIuJtwCHg+sw8cepOETEBTACMjIzQbrf7GFKr0R/ef4ITPxz8OKOTewf6+mvPhb/atHagY2h1iczs7YkRLeBB4NLMfCgiPgU8l5l/eqbntFqtPHjwYG8z1ao1OrmX4zuuGugY7Xab8fHxgY6xFP8O/WiKiEOZ2Zq7vZ8/Yj4BPJGZD3W+vhP4uT5eT5K0CD0HPDO/C3w7Ii7ubNoEHG1kVpKkBfX7LpQtwB2dd6D8O/A7/U9JktSNvgKemY8Cpx2XkSQNnmdiSlJRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklRU3wGPiHMi4pGI+McmJiRJ6k4TK/DrgWMNvI4kaRH6CnhEXARcBXy6melIkrq1ps/n/wXwMWDdmXaIiAlgAmBkZIR2u93nkFpt1r15krfcNjn4gW4b7MuvezO022sHO4hWlZ4DHhFXA09n5qGIGD/Tfpk5DUwDtFqtHB8/467SvJ6f3MHxHVcNdIx2u82gfzdHJ/cyfu1gx9Dq0s8hlEuBX42I48DfAZdHxO2NzEqStKCeA56ZH8/MizJzFLgG+GJmfqixmUmSzsr3gUtSUf3+EROAzGwD7SZeS5LUHVfgklSUAZekogy4JBVlwCWpKAMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJamoRi5mJQ3a6OTewQ+yb7BjXPDqcwf6+lp9DLhWvEHfjQdm/4NYinGkJnkIRZKKMuCSVJQBl6SiDLgkFWXAJakoAy5JRRlwSSrKgEtSUQZckooy4JJUlAGXpKIMuCQVZcAlqaieAx4RPxER+yPiWER8NSKub3JikqSz6+dysieBP87MhyNiHXAoIu7LzKMNzU2SdBY9r8Az88nMfLjz+HngGPCGpiYmSTq7Rm7oEBGjwM8CD83zvQlgAmBkZIR2u93EkFLj/N1UNX0HPCLOB+4CPpKZz839fmZOA9MArVYrx8fH+x1Sat6+vfi7qWr6ehdKRJzLbLzvyMzPNTMlSVI3+nkXSgCfAY5l5q7mpiRJ6kY/K/BLgQ8Dl0fEo52PX2loXpKkBfR8DDwz/xmIBuciSVoEz8SUpKIMuCQVZcAlqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekogy4JBVlwCWpKAMuSUU1ckceaaWZvdrxIp+zc/HjZObinyQ1xBW4fiRl5qI+9u/fv+jnGG8tNwMuSUUZcEkqyoBLUlEGXJKKMuCSVJQBl6SiDLgkFWXAJamoWMqTESLiGeCbSzag1L0NwPeWexLSGfxkZl44d+OSBlxaqSLiYGa2lnse0mJ4CEWSijLgklSUAZdmTS/3BKTF8hi4JBXlClySijLgklSUAdeKFhHrI+IPFthnNCJ+q4vXGo2II83Nbt4xbo2I9w9yDOllBlwr3XrgrAEHRoEFA960iDhnqceUTmXAtdLtAH4mIh6NiE90Po5ExOGI+MAp+7y7s88NnZX2AxHxcOfjnXNfNCK+EBFv7Tx+JCL+rPP4zyPi92PWaWNFxHhE7I+IvwUOd/b7y4g4GhF7gdedMsaOzvbHIuKTA/45aRXypsZa6SaBSzLz7RHx68Bm4G3Mnvr+5Yg40Nnno5l5NUBEnAdckZk/iIg3AnuAuWdZHmA2+seBk8Clne3vAm4H3ge8fZ6xAH6hM6fHI+J9wMXAW4AR4ChwS0S8Fvg14E2ZmRGxvsGfiQS4Alct7wL2ZOZ/Z+ZTwD8BPz/PfucCuyPiMPBZYGyefR4ALuu85l7g/E74RzPz3xYY60uZ+Xjn8WWn7Pcd4Iud7c8BPwA+3Yn8i339y6V5GHBVEl3udwPwFLOr5xbwqnn2+XLne+9mdjX+CHAdcKiLsU7M+fq0kyky8ySzK/W7gPcC+7qcu9Q1A66V7nlgXefxAeADEXFORFzI7Or3S3P2AbgAeDIz/wf4MHDaHxsz8yXg28BvAg8yuyL/aOfz2caa6wBwTWe/1wMbASLifOCCzPwC8BFmD8dIjfIYuFa0zHw2Iv6l8/a/e4DHgK8wu+r9WGZ+NyKeBU5GxFeAW4G/Bu6KiN8A9nP6ivllDwCbMvPFiHgAuIj/C/jdwDvmGetNc17jbuBy4DDwdWYPtcDsfyifj4hhZlfzN/Tzc5Dm46n0klSUh1AkqSgDLklFGXBJKsqAS1JRBlySijLgklSUAZekov4XA+9IfxVjWFYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Boxplot of the Totalwords column \n",
    "df_fin.boxplot(column =\"total words\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\basti\\AppData\\Local\\Temp/ipykernel_14680/1583998216.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  unique = set(df[0].str.replace('[^a-zA-Z ]', '').str.lower().str.split(' ').sum())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>best</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crichton</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2554</th>\n",
       "      <td>doublespeak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>visit</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>okay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>reefer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>madness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2559 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            index    0\n",
       "0             one   45\n",
       "1              of  177\n",
       "2             the  290\n",
       "3            best   44\n",
       "4        crichton    2\n",
       "...           ...  ...\n",
       "2554  doublespeak    1\n",
       "2555        visit    1\n",
       "2556         okay    1\n",
       "2557       reefer    1\n",
       "2558      madness    1\n",
       "\n",
       "[2559 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# - Calculate the number of unique words in the dataset\n",
    "# getting the data reday to apply the count. \n",
    "unique = set(df[0].str.replace('[^a-zA-Z ]', '').str.lower().str.split(' ').sum())\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "df = pd.DataFrame(data)\n",
    "unique = Counter()\n",
    "df[0].str.lower().str.split().apply(unique.update)\n",
    "\n",
    "\n",
    "# convert the count item into a dataframe\n",
    "df_counted = pd.DataFrame.from_dict(unique, orient = \"index\").reset_index()\n",
    "df_counted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "_XXnArgcII4i",
    "outputId": "020b2ee2-4c2a-4bc0-bb55-e2ae3841fe57",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one of the best crichton novels', 'the medicine of the future', 'beautiful', 'for lovers of robicheaux', 'a good book']\n",
      "[[18, 4, 2, 19], [2, 4, 2], [], [6, 4], [1, 12, 3]]\n"
     ]
    }
   ],
   "source": [
    "# Do not modify - Tokenize the vocabulary \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=25)\n",
    "\n",
    "tokenizer.fit_on_texts(data) #create the vocabularry\n",
    "\n",
    "tokenized_data = tokenizer.texts_to_sequences(data) #tokenize the data using the vocabulary\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1 \n",
    "\n",
    "# Compare a sample of the data before and after tokenization\n",
    "print(data[0:5])\n",
    "print(tokenized_data[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_vsMmLjdK1Gf"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "24DaXd1zII4q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18  4  2 19]\n",
      " [ 2  4  2  0]\n",
      " [ 0  0  0  0]\n",
      " ...\n",
      " [ 0  0  0  0]\n",
      " [ 6  0  0  0]\n",
      " [ 0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# Pre-processing\n",
    "# Write some code to pre-process the data so that each review is the same length\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data4 = pad_sequences(tokenized_data, padding = \"post\" , maxlen = 4)\n",
    "print(data4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AFTJcFy6II4s",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1434, 4)\n"
     ]
    }
   ],
   "source": [
    "# Write some code to split the data into a training and test set. Make sure you shuffle the data. Use 20% for the test set.\n",
    "\n",
    "X = data4\n",
    "y= labels\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.20, shuffle = True)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "lDth1BSzII4u",
    "outputId": "4614049a-7151-4407-9bc8-54604bbe7fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.34      0.41       176\n",
      "           1       0.53      0.71      0.60       183\n",
      "\n",
      "    accuracy                           0.53       359\n",
      "   macro avg       0.53      0.52      0.51       359\n",
      "weighted avg       0.53      0.53      0.51       359\n",
      "\n",
      "  \n",
      "conf_matrix\n",
      "    0    1\n",
      "0  59  117\n",
      "1  53  130\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def assess_model(model, X_test, y_test):      \n",
    "    #To do\n",
    "    y_pred = ()\n",
    "    con = ()\n",
    "    log = model()\n",
    "    log.fit(X_train, to_class(y_train))\n",
    "    y_pred = log.predict(X_test).reshape(-1,1)\n",
    "  \n",
    "    print(\"classification_report\")\n",
    "    print(classification_report(to_class(y_test),y_pred))\n",
    "    \n",
    "    print(\"  \")\n",
    "    print(\"conf_matrix\")\n",
    "    \n",
    "    conf_mat = confusion_matrix(to_class(y_test), y_pred)\n",
    "    cm = pd.DataFrame(conf_mat)\n",
    "    cm\n",
    "    print(cm)\n",
    "    \n",
    "assess_model(LogisticRegression, X_test, y_test)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Fill in the following function so it\n",
    "# - makes a prediction for the test set given the model\n",
    "# - reports the precision, recall and f1 score. Also print the confusion matrix. \n",
    "# You will need to use the helper to_class function to convert y_pred and y_test before supplying them to the sklearn functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTqLbbE6MpGt"
   },
   "source": [
    "# Build and tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3X70rA4uMXNv"
   },
   "source": [
    "Define network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKoXWKG4II5F",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Embedding class\n",
    "inputdim = 2600\n",
    "outputdim = 35\n",
    "inputlength = 4\n",
    "\n",
    "# importing the layers needed from keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(inputdim, outputdim, input_length = 4))\n",
    "model.add(BatchNormalization())\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(LSTM(32))  \n",
    "model.add(Dense(2 ,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "llS0-VKBMbz-"
   },
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# outputdim of 10\n",
    "inputdim = 2600\n",
    "outputdim = 10\n",
    "inputlength = 4\n",
    "ep = 5\n",
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5IJs0QuMe_I"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/590170741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model1.fit(X_train, y_train, batch_size=bs, epochs=ep )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# outputdim of 25\n",
    "inputdim = 2600\n",
    "outputdim = 25\n",
    "inputlength = 4\n",
    "ep = 5\n",
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train, y_train, batch_size=bs, epochs=ep )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model3 = model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# outputdim of 50\n",
    "inputdim = 2600\n",
    "outputdim = 50\n",
    "inputlength = 4\n",
    "ep = 5\n",
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/3221748268.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model3' is not defined"
     ]
    }
   ],
   "source": [
    "model3.fit(X_train, y_train, batch_size=bs, epochs=ep )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# outputdim of 100\n",
    "inputdim = 2600\n",
    "outputdim = 100\n",
    "inputlength = 4\n",
    "ep = 5\n",
    "bs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/1637307947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mep\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "model4.fit(X_train, y_train, batch_size=bs, epochs=ep )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rniBBEiyMRKD"
   },
   "source": [
    "Examine performance of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eBVogHg2II5T",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1179 test_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3309 sparse_categorical_accuracy\n        return math_ops.cast(math_ops.equal(y_true, y_pred), K.floatx())\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1614 equal\n        return gen_math_ops.equal(x, y, name=name)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:3221 equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 2 and 4 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,2], [?,4].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/282135666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[0;32m   1377\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TraceContext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1379\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1380\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    821\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m--> 696\u001b[1;33m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m    697\u001b[0m             *args, **kwds))\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2854\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2855\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2856\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3213\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3215\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3065\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 986\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    987\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    988\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    598\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    971\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    972\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    974\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1224 test_function  *\n        return step_function(self, iterator)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1215 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1208 run_step  **\n        outputs = model.test_step(data)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1179 test_step\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\compile_utils.py:409 update_state\n        metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py:90 decorated\n        update_op = update_state_fn(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:176 update_state_fn\n        return ag_update_state(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:612 update_state  **\n        matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:3309 sparse_categorical_accuracy\n        return math_ops.cast(math_ops.equal(y_true, y_pred), K.floatx())\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:201 wrapper\n        return target(*args, **kwargs)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1614 equal\n        return gen_math_ops.equal(x, y, name=name)\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:3221 equal\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:742 _apply_op_helper\n        op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:591 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3477 _create_op_internal\n        ret = Operation(\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1974 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\basti\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1815 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimensions must be equal, but are 2 and 4 for '{{node Equal}} = Equal[T=DT_FLOAT, incompatible_shape_error=true](IteratorGetNext:1, Cast_1)' with input shapes: [?,2], [?,4].\n"
     ]
    }
   ],
   "source": [
    "# evaluate model 1\n",
    "s = model1.evaluate(X_test, y_test)\n",
    "print(\"score\")\n",
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model 2\n",
    "s = model2.evaluate(X_test, y_test)\n",
    "print(\"score\")\n",
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model 3\n",
    "s = model3.evaluate(X_test, y_test)\n",
    "print(\"score\")\n",
    "print(s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/1629559358.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# evaluate model 4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"score\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model4' is not defined"
     ]
    }
   ],
   "source": [
    "# evaluate model 4\n",
    "s = model4.evaluate(X_test, y_test)\n",
    "print(\"score\")\n",
    "print(s[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Picking the final model based on score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_final = model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HB8kzt-IME4U"
   },
   "source": [
    "Plot graphs for accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPyJ78unMJUI"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/3466215448.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# Plot of the Accuracy of the model\n",
    "\n",
    "history = model_final\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show\n",
    "\n",
    "# this code was adatped form https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/700071435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Plot of the Accuracy of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# Plot of the Accuracy of the model\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# this code was adatped form https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eAZ1LyFBMLoK"
   },
   "source": [
    "# Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vfPM5LokII5V",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative', 'positive', 'negative', 'positive', 'positive']\n",
      "[1, 0, 1, 0, 0]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14680/452543380.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_final\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# This is a very small set of completed new data to use to make predictions.\n",
    "prediction_data = [\"this book is fabulous\",\"i hated this book\", \"the best\", \"no good\", \"okay\"]\n",
    "tokenized = tokenizer.texts_to_sequences(prediction_data)\n",
    "padded = pad_sequences(tokenized, padding='post', maxlen=4)\n",
    "\n",
    "\n",
    "# Supply this data to each of your models and see how it does. \n",
    "# You can call the helper function \"to_word_label\" to map the output of the model to the name of the\n",
    "# class it was predicted to belong to.\n",
    "\n",
    "\n",
    "data_test = to_word_label(padded)\n",
    "print(data_test)\n",
    "\n",
    "data_1 = []\n",
    "for i in range(0,5):\n",
    "    d = data_test[i]\n",
    "    if d == 'positive':\n",
    "        data_1.append(0)\n",
    "    else:\n",
    "        data_1.append(1)\n",
    "print(data_1)\n",
    "\n",
    "pred = model_final(data_1)\n",
    "for i in range(0,5):\n",
    "    \n",
    "    print(i)\n",
    "    print(\"predition\")\n",
    "    print(pred(i))\n",
    "    print(\"test y\")\n",
    "    print(y_test[i])\n",
    "    print(\"       \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "L3T20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
